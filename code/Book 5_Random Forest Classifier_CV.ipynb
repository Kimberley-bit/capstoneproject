{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "493dcdae",
   "metadata": {},
   "source": [
    "## Book 5_Random Forest Classifier_CV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569f72c4",
   "metadata": {},
   "source": [
    "*Note: I was unable to upload all of the datasets that I have used in these notebooks onto github because of how big the size of the file was. But if you have any questions feel free to reach out to me thank you :)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3f0199",
   "metadata": {},
   "source": [
    "This book will focus on the count vectoriser model and the random forest model.\n",
    "    \n",
    "    1.1: Preparing the data for training the model \n",
    "    1.2: Building a Random Forest model\n",
    "    1.3: Evaluating the model on the test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48e58dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# for modelling\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, plot_roc_curve, plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for Model Tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from time import time\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, plot_roc_curve, plot_confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from time import time\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "import graphviz \n",
    "# pip install grpahviz\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ea64d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce1bd3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing CV\n",
    "X_counts_df = pd.read_csv('../data/X_counts_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ab2aab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing \n",
    "suicide_merged = pd.read_csv('../data/suicide_merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c28bc541",
   "metadata": {},
   "outputs": [],
   "source": [
    "di = {'suicide': 1, 'non-suicide' : 0}\n",
    "suicide_merged['class'] = suicide_merged['class'].map(di)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c070f5dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 15)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suicide_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6daba3f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2000\n",
       "1    2000\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suicide_merged['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "852bb9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigning X and y \n",
    "X = X_counts_df\n",
    "y = suicide_merged['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8f344e",
   "metadata": {},
   "source": [
    "### 1.1: Preparing the data for training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf2ec175",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea21ef8",
   "metadata": {},
   "source": [
    "### 1.2: Building a Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80987530",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier(n_estimators=200, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b078a3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_array = np.ravel(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c1b6dfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=200, random_state=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "420da962",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e7f355",
   "metadata": {},
   "source": [
    "### 1.3: Evaluating the model on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a824484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.88      0.93       498\n",
      "           1       0.89      0.99      0.94       502\n",
      "\n",
      "    accuracy                           0.94      1000\n",
      "   macro avg       0.94      0.93      0.93      1000\n",
      "weighted avg       0.94      0.94      0.93      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52a0e365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.935\n",
      "precision score: 0.8894830659536542\n",
      "recall score: 0.9940239043824701\n",
      "specificity score: 0.8755020080321285\n"
     ]
    }
   ],
   "source": [
    "# Current score without tuning\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "# scores\n",
    "accuracy_score = accuracy_score(y_test, y_pred)\n",
    "precision_score = precision_score(y_test, y_pred)\n",
    "recall_score = recall_score = recall_score(y_test, y_pred)\n",
    "specificity_score = tn / (tn + fp)\n",
    "\n",
    "print('accuracy score: ' + str(accuracy_score))\n",
    "print('precision score: ' + str(precision_score))\n",
    "print('recall score: ' + str(recall_score))\n",
    "print('specificity score: ' + str(specificity_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d09acf51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 0 1 0 1 1 1 1 1 0 0 1 1 0 1 1 1 0 0 1 0 0 1 1 1 0 0 0 0 1 0 0 1 1\n",
      " 0 0 1 0 0 1 1 1 1 0 1 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0 1 0 0 1 1 0 1 0 1 1 1\n",
      " 1 1 1 0 1 0 0 1 0 1 1 1 1 0 0 0 0 0 1 1 0 0 0 1 0 1 1 0 0 1 0 1 1 1 1 1 1\n",
      " 0 1 0 0 1 1 0 1 1 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 1 1 1 0 0 0 0 1 1 1 0 0\n",
      " 0 1 0 0 1 0 1 1 0 1 0 0 1 1 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1 0 1 0 0 1 0 1\n",
      " 1 1 0 1 0 0 1 1 0 0 0 1 0 1 1 0 1 0 1 0 0 1 1 1 0 0 1 0 0 0 1 0 0 1 1 1 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 1 1 0 0 1 0 0 1 0 1 1 1 1 1 0 1 0 1 0 1 0 1 0 0 1\n",
      " 1 1 1 0 0 0 0 1 1 1 0 1 1 0 0 0 1 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 1 1 0 0 1 0 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 0 1 1 1\n",
      " 0 1 0 1 1 1 0 0 0 1 0 0 0 1 0 0 0 1 1 0 1 0 1 1 1 1 0 1 0 1 1 0 1 0 0 0 1\n",
      " 1 0 0 1 0 0 1 1 0 1 1 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1\n",
      " 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 1 0 1 1 0 0 0\n",
      " 0 0 1 1 1 1 1 1 0 1 1 0 0 0 0 1 1 1 1 0 1 0 1 0 1 0 1 0 1 1 1 1 0 0 1 0 1\n",
      " 1 0 0 1 0 1 1 1 0 0 1 1 1 0 0 1 1 0 1 0 0 0 1 0 0 1 0 0 1 1 1 1 0 0 0 0 1\n",
      " 1 1 0 1 1 1 0 0 0 0 0 1 1 1 0 0 1 0 1 1 0 1 0 1 1 0 1 0 1 1 1 0 0 1 0 0 1\n",
      " 0 0 1 0 0 1 1 1 0 1 1 1 0 0 0 0 0 1 1 1 0 0 1 1 1 0 0 1 1 1 1 0 0 1 1 0 0\n",
      " 1 1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 1 1 1 0 0 1 0 0 0 0 1 1 0 0 0 0 1\n",
      " 1 1 1 0 0 1 1 1 1 1 0 0 0 0 1 0 1 0 0 0 1 1 1 1 1 0 0 1 1 1 1 0 0 1 1 0 0\n",
      " 0 1 0 0 1 1 1 1 1 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 1 1 1 0 1 1\n",
      " 1 0 0 0 0 1 0 1 1 0 0 1 1 0 0 0 0 1 0 1 1 0 1 1 0 0 0 1 0 0 1 0 1 0 1 0 0\n",
      " 1 0 1 1 0 0 0 1 0 0 1 0 0 0 1 1 0 0 1 0 0 1 0 0 1 0 0 0 1 1 0 0 0 0 1 0 1\n",
      " 1 1 1 1 1 0 1 1 0 0 1 0 0 1 1 1 0 1 0 1 1 0 0 1 1 0 0 1 1 1 0 0 1 0 0 1 1\n",
      " 0 1 1 0 1 0 1 1 1 0 1 0 0 1 0 1 0 1 1 0 0 0 0 0 1 0 0 1 1 0 1 0 1 1 1 1 1\n",
      " 1 0 1 0 0 1 1 1 0 1 1 0 0 0 1 1 1 0 1 0 0 0 1 1 1 1 0 1 0 0 1 1 1 0 1 1 1\n",
      " 1 1 0 0 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 0 0 0 0 0 0 1 1 1 1 1 1 0 0 1 1\n",
      " 0 1 1 1 0 1 0 0 1 0 0 1 1 0 0 0 1 0 0 0 0 1 1 0 0 1 1 1 0 0 1 0 1 1 1 1 0\n",
      " 1 1 1 0 0 0 1 1 0 0 1 0 0 0 0 1 0 1 1 1 1 0 1 0 1 0 0 0 1 0 1 1 1 0 1 0 1\n",
      " 1]\n"
     ]
    }
   ],
   "source": [
    "y_test_array = np.ravel(y_test)\n",
    "print(y_test_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0870ece1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 0 1 0 1 1 1 1 1 0 0 1 1 0 1 1 1 0 0 1 0 1 1 1 1 1 0 0 0 1 1 0 1 1\n",
      " 0 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0 1 0 0 1 1 0 1 0 1 1 1\n",
      " 1 1 1 0 1 0 0 1 0 1 1 1 1 0 0 0 0 0 1 1 0 0 0 1 0 1 1 0 0 1 0 1 1 1 1 1 1\n",
      " 0 1 0 0 1 1 0 1 1 0 0 0 1 1 0 0 1 1 0 1 1 0 0 0 0 1 1 1 0 1 0 0 1 1 1 0 0\n",
      " 0 1 0 0 1 1 1 1 0 1 0 0 1 1 0 1 1 0 0 1 1 0 0 1 1 1 0 0 0 1 1 1 0 0 1 0 1\n",
      " 1 1 1 1 0 0 1 1 0 0 0 1 0 1 1 0 1 0 1 0 0 1 1 1 0 0 1 0 1 0 1 0 0 1 1 1 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 1 1 0 0 1 0 0 1 1 1 0 1 1 1 0 1 0 1 0 1 1 1 0 0 1\n",
      " 1 1 1 0 0 0 0 1 1 1 0 1 1 0 0 0 1 0 1 0 0 0 0 1 0 0 1 0 1 1 0 1 1 1 1 0 1\n",
      " 1 0 0 1 0 1 1 1 0 0 1 0 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1 1\n",
      " 0 1 0 1 1 1 0 0 0 1 0 0 0 1 0 0 0 1 1 0 1 0 1 1 1 1 0 1 0 1 1 0 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1\n",
      " 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 1 1 0 1 1 1 0 0\n",
      " 0 0 1 1 1 1 1 1 0 1 1 1 0 0 0 1 1 1 1 0 1 0 1 0 1 0 1 0 1 1 1 1 0 0 1 0 1\n",
      " 1 0 0 1 0 1 1 1 0 0 1 1 1 0 0 1 1 0 1 0 0 0 1 0 0 1 0 0 1 1 1 1 0 0 0 0 1\n",
      " 1 1 1 1 1 1 1 1 0 0 0 1 1 1 0 0 1 0 1 1 0 1 0 1 1 0 1 0 1 1 1 0 1 1 0 0 1\n",
      " 0 0 1 0 1 1 1 1 0 1 1 1 0 0 0 0 1 1 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 1 0 0\n",
      " 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 0 1 1 1 1 1 0 0 1 0 0 1 0 1 1 0 0 0 0 1\n",
      " 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 0\n",
      " 0 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 1 1 1 0 1 1\n",
      " 1 0 1 0 0 1 1 1 1 0 0 1 1 0 1 1 0 1 0 1 1 0 1 1 0 0 0 1 0 0 1 0 1 1 1 0 0\n",
      " 1 0 1 1 0 0 0 1 0 1 1 0 0 0 1 1 0 0 1 0 0 1 0 0 1 0 1 0 1 1 0 0 0 0 1 0 1\n",
      " 1 1 1 1 1 0 1 1 0 0 1 0 0 1 1 1 0 1 0 1 1 0 0 1 1 0 0 1 1 1 0 0 1 0 0 1 1\n",
      " 0 1 1 0 1 1 1 1 1 0 1 0 0 1 0 1 0 1 1 0 0 0 1 0 1 0 0 1 1 0 1 0 1 1 1 1 1\n",
      " 1 0 1 0 0 1 1 1 0 1 1 0 0 0 1 1 1 0 1 0 0 0 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1\n",
      " 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 0 0 0 0 0 0 1 1 1 1 1 1 0 0 1 1\n",
      " 0 1 1 1 0 1 0 0 1 0 0 1 1 0 0 0 1 0 0 0 0 1 1 1 0 1 1 1 0 0 1 0 1 1 1 1 1\n",
      " 1 1 1 0 0 0 1 1 0 0 1 0 1 0 0 1 0 0 1 1 1 0 1 0 1 0 0 0 1 1 1 1 1 0 1 0 1\n",
      " 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8521cc93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
